{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SN_256_128_x00\n",
      "Number of patches per image:  165\n",
      "49500 16500  =  49500 16500\n",
      "Batch size:  256\n",
      "Evaluate batch size:  256\n",
      "Steps per epoch:  194 193\n",
      "Validation steps per epoch:  65 64\n",
      "Channels last\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 84, 84, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 82, 82, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 41, 41, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 41, 41, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 120,836\n",
      "Trainable params: 120,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 49500 images belonging to 4 classes.\n",
      "Found 16500 images belonging to 4 classes.\n",
      "Steps per epoch: 194 65\n",
      "Epoch 1/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 1.3125 - acc: 0.3763Epoch 00001: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-01-1.31-0.38-1.23-0.45.hdf5\n",
      "194/194 [==============================] - 561s 3s/step - loss: 1.3122 - acc: 0.3764 - val_loss: 1.2272 - val_acc: 0.4485\n",
      "Epoch 2/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 1.1490 - acc: 0.4920Epoch 00002: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-02-1.15-0.49-1.22-0.48.hdf5\n",
      "194/194 [==============================] - 538s 3s/step - loss: 1.1487 - acc: 0.4921 - val_loss: 1.2200 - val_acc: 0.4764\n",
      "Epoch 3/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 1.0445 - acc: 0.5465Epoch 00003: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-03-1.05-0.55-1.26-0.47.hdf5\n",
      "194/194 [==============================] - 534s 3s/step - loss: 1.0447 - acc: 0.5464 - val_loss: 1.2601 - val_acc: 0.4744\n",
      "Epoch 4/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.9752 - acc: 0.5808Epoch 00004: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-04-0.97-0.58-1.18-0.53.hdf5\n",
      "194/194 [==============================] - 538s 3s/step - loss: 0.9749 - acc: 0.5809 - val_loss: 1.1772 - val_acc: 0.5305\n",
      "Epoch 5/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.8962 - acc: 0.6217Epoch 00005: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-05-0.90-0.62-1.11-0.54.hdf5\n",
      "194/194 [==============================] - 530s 3s/step - loss: 0.8961 - acc: 0.6218 - val_loss: 1.1077 - val_acc: 0.5426\n",
      "Epoch 6/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.8236 - acc: 0.6557Epoch 00006: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-06-0.82-0.66-1.16-0.55.hdf5\n",
      "194/194 [==============================] - 541s 3s/step - loss: 0.8238 - acc: 0.6557 - val_loss: 1.1560 - val_acc: 0.5521\n",
      "Epoch 7/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.7652 - acc: 0.6827Epoch 00007: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-07-0.77-0.68-1.22-0.56.hdf5\n",
      "194/194 [==============================] - 528s 3s/step - loss: 0.7655 - acc: 0.6827 - val_loss: 1.2215 - val_acc: 0.5561\n",
      "Epoch 8/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.7035 - acc: 0.7116Epoch 00008: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-08-0.70-0.71-1.11-0.59.hdf5\n",
      "194/194 [==============================] - 541s 3s/step - loss: 0.7034 - acc: 0.7116 - val_loss: 1.1099 - val_acc: 0.5904\n",
      "Epoch 9/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.6728 - acc: 0.7264Epoch 00009: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-09-0.67-0.73-1.21-0.56.hdf5\n",
      "194/194 [==============================] - 537s 3s/step - loss: 0.6727 - acc: 0.7265 - val_loss: 1.2137 - val_acc: 0.5643\n",
      "Epoch 10/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.6215 - acc: 0.7504Epoch 00010: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-10-0.62-0.75-1.15-0.57.hdf5\n",
      "194/194 [==============================] - 533s 3s/step - loss: 0.6209 - acc: 0.7506 - val_loss: 1.1505 - val_acc: 0.5740\n",
      "Epoch 11/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.5912 - acc: 0.7592Epoch 00011: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-11-0.59-0.76-1.14-0.59.hdf5\n",
      "194/194 [==============================] - 532s 3s/step - loss: 0.5907 - acc: 0.7595 - val_loss: 1.1391 - val_acc: 0.5872\n",
      "Epoch 12/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.5597 - acc: 0.7740Epoch 00012: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-12-0.56-0.77-1.18-0.59.hdf5\n",
      "194/194 [==============================] - 534s 3s/step - loss: 0.5594 - acc: 0.7741 - val_loss: 1.1773 - val_acc: 0.5924\n",
      "Epoch 13/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.5374 - acc: 0.7836Epoch 00013: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-13-0.54-0.78-1.37-0.57.hdf5\n",
      "194/194 [==============================] - 539s 3s/step - loss: 0.5377 - acc: 0.7835 - val_loss: 1.3678 - val_acc: 0.5682\n",
      "Epoch 14/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.5011 - acc: 0.7994Epoch 00014: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-14-0.50-0.80-1.22-0.61.hdf5\n",
      "194/194 [==============================] - 531s 3s/step - loss: 0.5004 - acc: 0.7998 - val_loss: 1.2171 - val_acc: 0.6083\n",
      "Epoch 15/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.4807 - acc: 0.8072Epoch 00015: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-15-0.48-0.81-1.26-0.61.hdf5\n",
      "194/194 [==============================] - 528s 3s/step - loss: 0.4811 - acc: 0.8069 - val_loss: 1.2585 - val_acc: 0.6056\n",
      "Epoch 16/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.4561 - acc: 0.8174Epoch 00016: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-16-0.46-0.82-1.41-0.58.hdf5\n",
      "194/194 [==============================] - 534s 3s/step - loss: 0.4561 - acc: 0.8174 - val_loss: 1.4134 - val_acc: 0.5807\n",
      "Epoch 17/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.4400 - acc: 0.8242Epoch 00017: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-17-0.44-0.82-1.31-0.57.hdf5\n",
      "194/194 [==============================] - 530s 3s/step - loss: 0.4399 - acc: 0.8242 - val_loss: 1.3085 - val_acc: 0.5735\n",
      "Epoch 18/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.4115 - acc: 0.8364Epoch 00018: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-18-0.41-0.84-1.40-0.59.hdf5\n",
      "194/194 [==============================] - 526s 3s/step - loss: 0.4114 - acc: 0.8364 - val_loss: 1.3993 - val_acc: 0.5902\n",
      "Epoch 19/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3959 - acc: 0.8450Epoch 00019: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-19-0.40-0.85-1.43-0.59.hdf5\n",
      "194/194 [==============================] - 536s 3s/step - loss: 0.3957 - acc: 0.8452 - val_loss: 1.4251 - val_acc: 0.5870\n",
      "Epoch 20/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3828 - acc: 0.8494Epoch 00020: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-20-0.38-0.85-1.55-0.58.hdf5\n",
      "194/194 [==============================] - 532s 3s/step - loss: 0.3828 - acc: 0.8494 - val_loss: 1.5530 - val_acc: 0.5766\n",
      "Epoch 21/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3649 - acc: 0.8573Epoch 00021: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-21-0.37-0.86-1.47-0.58.hdf5\n",
      "194/194 [==============================] - 530s 3s/step - loss: 0.3652 - acc: 0.8572 - val_loss: 1.4676 - val_acc: 0.5808\n",
      "Epoch 22/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3487 - acc: 0.8636Epoch 00022: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-22-0.35-0.86-1.52-0.60.hdf5\n",
      "194/194 [==============================] - 534s 3s/step - loss: 0.3484 - acc: 0.8638 - val_loss: 1.5163 - val_acc: 0.6019\n",
      "Epoch 23/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3294 - acc: 0.8711Epoch 00023: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-23-0.33-0.87-1.44-0.60.hdf5\n",
      "194/194 [==============================] - 534s 3s/step - loss: 0.3294 - acc: 0.8711 - val_loss: 1.4399 - val_acc: 0.5999\n",
      "Epoch 24/1000\n",
      "193/194 [============================>.] - ETA: 2s - loss: 0.3269 - acc: 0.8722Epoch 00024: saving model to ./../Model/SN_256_128_x00/SN_256_128_x00_w-24-0.33-0.87-1.58-0.58.hdf5\n",
      "194/194 [==============================] - 527s 3s/step - loss: 0.3267 - acc: 0.8724 - val_loss: 1.5834 - val_acc: 0.5833\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# Patch-based Classification of Breast Cancer Histology Images using CNNs\n",
    "# LE48: MiniProject\n",
    "# Jan Ondras (jo356), Trinity College\n",
    "# 2017/2018\n",
    "##################################################################################################\n",
    "# Train CNN model                        (x type)\n",
    "##################################################################################\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import glob\n",
    "import os\n",
    "from time import time\n",
    "from math import ceil\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "seed = 7 #7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# seeds = [7, 34, 888, 456456, 33, 16947, 7764, 3396, 20500, 3009467] # 10 random seeds = 10 rand restarts\n",
    "\n",
    "# for seed_index, seed in enumerate(seeds): # 10 random restarts\n",
    "#     np.random.seed(seed)\n",
    "#     if seed == 7 or seed == 34:        # TO DELETE\n",
    "#         continue\n",
    "\n",
    "###################################################################################### TO SET\n",
    "overwrite = True\n",
    "overwrite = False\n",
    "\n",
    "# fixed_augment = True\n",
    "fixed_augment = False\n",
    "fixedAndRand_augment = False\n",
    "# fixedAndRand_augment = True\n",
    "\n",
    "N_patch_augment = 8\n",
    "\n",
    "target_size = (256,256)\n",
    "model_ID = 'x00' # + str(seed_index)\n",
    "patch_width = 256                     # 256, 512, 1024\n",
    "patch_height = patch_width\n",
    "patch_stride = 128                    # 256, 512\n",
    "model_type = 'SN_' + str(patch_width) + '_' + str(patch_stride) + '_' + model_ID\n",
    "\n",
    "RGB_means = [\n",
    "    180.375933345 , 148.276127037 , 174.592562423\n",
    "] \n",
    "# AWS: 180.375933345 , 148.276127037 , 174.592562423\n",
    "# HPC: 180.7795009644826 , 148.3537065177495 , 174.59451631969864\n",
    "######################################################################################\n",
    "# Create model directory for model checkpointing\n",
    "if overwrite == False:\n",
    "    if not os.path.exists('./../Model/' + model_type):\n",
    "        os.mkdir('./../Model/' + model_type)\n",
    "    else:\n",
    "        raise NameError('Model directory ' + './../Model/' + model_type + ' already exists!')\n",
    "model_checkpoint_path_prefix = './../Model/' + model_type + '/' + model_type + '_'\n",
    "print model_type\n",
    "\n",
    "# History file for checkpointing loss, acc and time per epoch\n",
    "history_filename = './../History/history_' + model_type + '.txt'\n",
    "if overwrite == False:\n",
    "    if os.path.exists(history_filename):\n",
    "        raise NameError('History file ' + history_filename + ' already exists!')\n",
    "\n",
    "classes = ['Normal', 'Benign', 'InSitu', 'Invasive'] # correspond to labels 0,1,2,3 in this order\n",
    "\n",
    "# Image size (assume same for all images)\n",
    "img_width =  2048\n",
    "img_height = 1536\n",
    "pix_scale = 0.42 # micrometers\n",
    "\n",
    "# Number of examples (whole images) per class before data augmentation\n",
    "# N_imgs_per_class = 100\n",
    "\n",
    "N_patches_x = (((img_width - patch_width) / patch_stride) + 1)\n",
    "N_patches_y = (((img_height - patch_height) / patch_stride) + 1)\n",
    "N_patches_per_img = N_patches_x * N_patches_y\n",
    "print \"Number of patches per image: \", N_patches_per_img\n",
    "\n",
    "path_prefix = './../Dataset/ICIAR2018_BACH_Challenge/Photos_SN/' \n",
    "train_valid_split = 0.75\n",
    "if fixed_augment:\n",
    "    train_data_dir = path_prefix+'aug_patches_' + str(patch_width) + '_' + str(patch_stride) + '_' + str(N_patch_augment) + '/train'\n",
    "else:\n",
    "    train_data_dir = path_prefix+'patches_' + str(patch_width) + '_' + str(patch_stride) + '/train'\n",
    "validation_data_dir = path_prefix+'patches_' + str(patch_width) + '_' + str(patch_stride) + '/validation'\n",
    "\n",
    "# N_train_samples = train_valid_split * N_imgs_per_class * len(classes) * N_patches_per_img\n",
    "# N_validation_samples = (1.-train_valid_split) * N_imgs_per_class * len(classes) * N_patches_per_img\n",
    "if fixed_augment:\n",
    "    N_train_samples = len(glob.glob(path_prefix+'aug_patches_' + str(patch_width) + '_' + str(patch_stride) + '_' + str(N_patch_augment) + '/train/*/*.tif'))\n",
    "    N_validation_samples = len(glob.glob(path_prefix+'patches_' + str(patch_width) + '_' + str(patch_stride) + '/validation/*/*.tif'))\n",
    "    print N_train_samples, N_validation_samples, \" = \", N_patch_augment*N_patches_per_img*300, N_patches_per_img*100\n",
    "else:\n",
    "    N_train_samples = len(glob.glob(path_prefix+'patches_' + str(patch_width) + '_' + str(patch_stride) + '/train/*/*.tif'))\n",
    "    N_validation_samples = len(glob.glob(path_prefix+'patches_' + str(patch_width) + '_' + str(patch_stride) + '/validation/*/*.tif'))\n",
    "    print N_train_samples, N_validation_samples, \" = \", N_patches_per_img*300, N_patches_per_img*100\n",
    "\n",
    "epochs = 1000\n",
    "train_batch_size = 256    #32\n",
    "evaluate_batch_size = 256 #64 #N_validation_samples\n",
    "steps_per_epoch =  int(ceil(float(N_train_samples) / train_batch_size))\n",
    "validation_steps = int(ceil(float(N_validation_samples) / evaluate_batch_size))\n",
    "print \"Batch size: \", train_batch_size\n",
    "print \"Evaluate batch size: \", evaluate_batch_size\n",
    "print \"Steps per epoch: \", steps_per_epoch, N_train_samples // train_batch_size\n",
    "print \"Validation steps per epoch: \", validation_steps, N_validation_samples // evaluate_batch_size\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, target_size[0], target_size[1])\n",
    "    print \"Channels first\"\n",
    "else:\n",
    "    input_shape = (target_size[0], target_size[1], 3) # this one\n",
    "    print \"Channels last\"\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "def substract_mean(patch):\n",
    "    # RGB\n",
    "    patch[:,:,0] -= RGB_means[0]\n",
    "    patch[:,:,1] -= RGB_means[1]\n",
    "    patch[:,:,2] -= RGB_means[2]    \n",
    "    return patch\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "#def create_model():\n",
    "# add dropout: Dropout(0.5) after dense\n",
    "# strides for pooling layer = pool size\n",
    "\n",
    "# TODO: kernel_initializer='he_uniform'\n",
    "\n",
    "# MODEL WITH BATCH NORMALISATION\n",
    "\n",
    "# inp = Input(shape=input_shape)\n",
    "# inpN = BatchNormalization()(inp)\n",
    "\n",
    "# c1 = Conv2D(16, (3, 3), strides=(1, 1), padding='valid', activation='relu')(inpN)\n",
    "# c1 = BatchNormalization()(c1)\n",
    "# p1 = MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid')(c1)\n",
    "# p1 = Dropout(0.1)(p1)\n",
    "\n",
    "# c2 = Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu')(p1)\n",
    "# c2 = BatchNormalization()(c2)\n",
    "# p2 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(c2)\n",
    "# p2 = Dropout(0.1)(p2)\n",
    "\n",
    "# c3 = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(p2)\n",
    "# c3 = BatchNormalization()(c3)\n",
    "# p3 = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(c3)\n",
    "# p3 = Dropout(0.1)(p3)\n",
    "\n",
    "# c4 = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(p3)\n",
    "# c4 = BatchNormalization()(c4)\n",
    "# p4 = MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid')(c4)\n",
    "# p4 = Dropout(0.1)(p4)\n",
    "\n",
    "# c5 = Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu')(p4)\n",
    "# c5 = BatchNormalization()(c5)\n",
    "# p5 = MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid')(c5)\n",
    "# p5 = Dropout(0.1)(p5)\n",
    "\n",
    "# f1 = Flatten()(p5)\n",
    "\n",
    "# d1 = Dense(256, activation='relu')(f1)\n",
    "# d1 = BatchNormalization()(d1)\n",
    "# d1 = Dropout(0.5)(d1)\n",
    "\n",
    "# d2 = Dense(128, activation='relu')(d1)\n",
    "# d2 = BatchNormalization()(d2)\n",
    "# d2 = Dropout(0.5)(d2)\n",
    "\n",
    "# out = Dense(4, activation='softmax')(d2)\n",
    "\n",
    "# model = Model(input=inp, output=out)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Conv2D(16, (3, 3), strides=(1, 1), padding='valid', input_shape=input_shape, activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "#         Dropout(0.1),\n",
    "\n",
    "    Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'),\n",
    "#         Dropout(0.1),\n",
    "\n",
    "    Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'),\n",
    "#         Dropout(0.1),\n",
    "\n",
    "    Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "#         Dropout(0.1),\n",
    "\n",
    "    Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "#         Dropout(0.1),\n",
    "    \n",
    "    # Below is with He init\n",
    "#     Conv2D(16, (3, 3), strides=(1, 1), padding='valid', input_shape=input_shape, activation='relu', kernel_initializer='he_uniform'),\n",
    "#     MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "# #     Dropout(0.1),\n",
    "\n",
    "#     Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu', kernel_initializer='he_uniform'),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'),\n",
    "# #     Dropout(0.1),\n",
    "\n",
    "#     Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'),\n",
    "# #     Dropout(0.1),\n",
    "\n",
    "#     Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "#     MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "# #     Dropout(0.1),\n",
    "\n",
    "#     Conv2D(32, (3, 3), strides=(1, 1), padding='valid', activation='relu', kernel_initializer='he_uniform'),\n",
    "#     MaxPooling2D(pool_size=(3, 3), strides=None, padding='valid'),\n",
    "# #     Dropout(0.1),\n",
    "\n",
    "    Flatten(),\n",
    "#     Dense(256, activation='relu', kernel_initializer='he_uniform'),\n",
    "    Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "    Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "# Run on 8 GPUs\n",
    "# model = multi_gpu_model(model, gpus=4)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(), # 'adadelta' rmsprop adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For fixed augmentation\n",
    "if fixed_augment:\n",
    "    # Both\n",
    "    if fixedAndRand_augment:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=substract_mean, \n",
    "            rotation_range=45, \n",
    "            fill_mode='reflect' # reflect / wrap / nearest\n",
    "        ) \n",
    "    # Fixed augment only\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=substract_mean, \n",
    "        ) \n",
    "# Random augmentation only\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=substract_mean, \n",
    "        rotation_range=180, \n",
    "        horizontal_flip=True, \n",
    "        fill_mode='reflect' # reflect / wrap / nearest\n",
    "            #rotation_range=45, \n",
    "            #rescale=1./255,\n",
    "            #horizontal_flip=True,\n",
    "            #vertical_flip=True,\n",
    "            #fill_mode='reflect'\n",
    "    ) \n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=substract_mean\n",
    ")\n",
    "\n",
    "# Data generator takes care of one hot encoding # one_hot_labels = keras.utils.to_categorical(labels, num_classes=4)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=classes)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=evaluate_batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=classes)\n",
    "\n",
    "print \"Steps per epoch:\", len(train_generator), len(validation_generator)\n",
    "if len(train_generator) != steps_per_epoch:\n",
    "    raise ValueError('Check train steps per epoch!')\n",
    "if len(validation_generator) != validation_steps:\n",
    "    raise ValueError('Check valid steps per epoch!')\n",
    "\n",
    "# Checkpoint model weights and the model itself\n",
    "model_checkpoint_name = 'w-{epoch:02d}-{loss:.2f}-{acc:.2f}-{val_loss:.2f}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_checkpoint_path_prefix + model_checkpoint_name, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# Checkpoint loss and acc for val and train after every epoch\n",
    "class ModelHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "        self.times = []\n",
    "        with open(history_filename, 'w') as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime=time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time()-self.starttime)\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        with open(history_filename, 'a') as f:\n",
    "            f.write( str(logs.get('loss')) + \",\" + str(logs.get('acc')) + \",\" \n",
    "                    + str(logs.get('val_loss')) + \",\" + str(logs.get('val_acc')) + \",\" + str(self.times[-1]) + \"\\n\")\n",
    "\n",
    "model_hist = ModelHistory()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=10, verbose=1) \n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = steps_per_epoch, \n",
    "    #steps_per_epoch=N_train_samples // train_batch_size,             # wrong!\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator, \n",
    "    validation_steps = validation_steps, \n",
    "    #validation_steps=N_validation_samples // evaluate_batch_size,    # wrong!\n",
    "    verbose=1,\n",
    "    shuffle=True, \n",
    "    callbacks=[model_checkpoint, model_hist, early_stop]\n",
    "    #use_multiprocessing=True,\n",
    "    #workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# OLD, not used\n",
    "\n",
    "##############################################################################\n",
    "# Plot training and validation loss and accuracy curves\n",
    "# Plot training times per epoch\n",
    "##############################################################################\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = range(1, len(model_hist.times)+1)\n",
    "\n",
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(x, model_hist.train_loss,'ro-')#,linewidth=2.0)\n",
    "plt.plot(x, model_hist.val_loss,'bo-')#,linewidth=2.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'])#,fontsize=18)\n",
    "plt.xticks(x, x)\n",
    "plt.xlabel('Epoch')#,fontsize=16)\n",
    "plt.ylabel('Loss')#,fontsize=16)\n",
    "# plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(x, model_hist.train_acc,'ro-')#,linewidth=2.0)\n",
    "plt.plot(x, model_hist.val_acc,'bo-')#,linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])#,fontsize=18)\n",
    "plt.xticks(x, x)\n",
    "plt.xlabel('Epoch')#,fontsize=16)\n",
    "plt.ylabel('Accuracy')#,fontsize=16)\n",
    "# plt.title('Accuracy Curves',fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Training time\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(x, np.array(model_hist.times)/60., 'o-')\n",
    "plt.xticks(x, x)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training time per epoch (min)')\n",
    "plt.legend(['Mean = '+str(np.mean(model_hist.times)/60.)+\" min\"])\n",
    "plt.show()\n",
    "\n",
    "# Oly if whole training completes ...\n",
    "# # Loss Curves\n",
    "# plt.figure(figsize=[8,6])\n",
    "# plt.plot(history.history['loss'],'r',linewidth=2.0)\n",
    "# plt.plot(history.history['val_loss'],'b',linewidth=2.0)\n",
    "# plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "# plt.xlabel('Epochs ',fontsize=16)\n",
    "# plt.ylabel('Loss',fontsize=16)\n",
    "# plt.title('Loss Curves',fontsize=16)\n",
    "# # Accuracy Curves\n",
    "# plt.figure(figsize=[8,6])\n",
    "# plt.plot(history.history['acc'],'r',linewidth=2.0)\n",
    "# plt.plot(history.history['val_acc'],'b',linewidth=2.0)\n",
    "# plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "# plt.xlabel('Epochs ',fontsize=16)\n",
    "# plt.ylabel('Accuracy',fontsize=16)\n",
    "# plt.title('Accuracy Curves',fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # just to check\n",
    "    # print train_generator.class_indices, train_generator.classes\n",
    "    # print validation_generator.class_indices, validation_generator.classes\n",
    "\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    # model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # Reduce learning rate when val_loss stopped improving\n",
    "    # reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "    #                               patience=5, min_lr=0.001)\n",
    "    # model.fit(X_train, Y_train, callbacks=[reduce_lr])\n",
    "    # or: keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "# Custom generator\n",
    "# https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs\n",
    "# def generate_arrays_from_file(path):\n",
    "#     while 1:\n",
    "#         f = open(path)\n",
    "#         for line in f:\n",
    "#             # create numpy arrays of input data\n",
    "#             # and labels, from each line in the file\n",
    "#             x1, x2, y = process_line(line)\n",
    "#             yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "#         f.close()\n",
    "\n",
    "# model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
    "#                     steps_per_epoch=10000, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
